# text-autocomplete
Репозиторий для проекта второго спринта. Цель проекта - собрать и нейронную сеть LSTM и обучить ее дополнять текст.

**ПРИМЕЧАНИЕ**: В связи с проблемой при подключении к виртуальной машине модель обучена локально на небольшой части датасета. Поэтому метрики качества прогнозов нерелевантны, а пункт с написанием выводов оставлен пустам. Просьба осуществить ревью проекта в его текущем виде. Проблему с подключением на данный момент устранить не удалось.

В данном проекте осуществляется:
  1. Сбор и подготовка данных (очистка, токенизация, разделение на выборки), создаются Dataset-ы и DataLoader-ы.
  2. Создается модель LSTM с помощью библиотеки torch
  3. Модель обучается на коротком датасете (10 тыс. предложений). Затем решается задача предсказания 1/4 текста по предыдущим 3/4. Выводятся метрики Loss (на обучающей выборке) и ROUGE-1, ROUGE-2 на валидационной выборке. Веса модели сохраняются.
  4. Для сравнения решается та же задача, но с помощью предобученной модели distilgpt2. Для нее считаются метрики ROUGE-1 и ROUGE-2 на валидационной выборке.
  5. Раздел формулирование выводов оставлен пустым в связи с невозможностью подключения к виртуальной машине для обучения модели на полном датасете (1.6 млн предложений).

Ноутбук (solution.ipynb) лежит в корне проекта.
