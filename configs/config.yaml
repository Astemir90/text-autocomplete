lstm_model:
  batch_size: 256
  embed_dim: 128
  hidden_dim: 128
  n_layers: 2
  generated_max_length: 20
  lr: 0.001

eval_lstm:
  good_cases_displayed: 5
  bad_cases_displayed: 5

lstm_train:
  n_epochs: 3

transformer:
  top_k: 50
  max_new_tokens: 20